{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JECcapCZtXy5"
      },
      "source": [
        "# project name: Sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWJ7qbjrtXzF"
      },
      "source": [
        "# Step 0. Read in Data and NLTK Basics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEFv9ruubTgw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('ggplot')\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('popular')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FJYXLBi22ph"
      },
      "outputs": [],
      "source": [
        "# Read in data\n",
        "df = pd.read_csv('D:/Reviews.csv')\n",
        "print('the shape of all dataset is: ',df.shape)\n",
        "print(\"Dataset size:\", len(df))\n",
        "df=df.head(100)\n",
        "print('the shape of our data is: ' ,df.shape )\n",
        "print(\"Dataset size:\", len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aw1rAxu4tXzP"
      },
      "outputs": [],
      "source": [
        "print('the first 5 review is: ')\n",
        "print(' ')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6Ugj0UXtXzR"
      },
      "outputs": [],
      "source": [
        "print('the last 5 review is: ')\n",
        "print('')\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5C1AE9BtXzS"
      },
      "outputs": [],
      "source": [
        "print('the shape of data is: ',df.shape)\n",
        "\n",
        "print(\"Dataset size:\", len(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXz0jmh2tXzU"
      },
      "outputs": [],
      "source": [
        "\n",
        "print('th information of data is:')\n",
        "print('')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fVZd4yXtXzW"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjNgl3MdtXzX"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Svl01NuptXzZ"
      },
      "outputs": [],
      "source": [
        "df.describe(include=\"O\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HjsW26wtXzb"
      },
      "outputs": [],
      "source": [
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkBAHCi4tXzc"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp8aNKHLtXze"
      },
      "source": [
        "# #Data Cleaning\n",
        "\n",
        "    Check Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of6_UMRbtXze"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srIkRw1btXzf"
      },
      "source": [
        "#  Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMCTHCCstXzg"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoUnbPPPtXzh"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from  nltk.stem import SnowballStemmer\n",
        "\n",
        "stop_words = stopwords.words(\"english\")\n",
        "stemmer = SnowballStemmer(\"english\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_lg07R7tXzh"
      },
      "source": [
        "# Quick EDA and visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1nYsn295Ll9"
      },
      "outputs": [],
      "source": [
        "ax = df['Score'].value_counts().sort_index() \\\n",
        "    .plot(kind='bar',\n",
        "          title='Count of Reviews by Stars',\n",
        "          figsize=(5, 2.5))\n",
        "ax.set_xlabel('Review Stars')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S8NtW2htXzj"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dcYe9RqtXzk"
      },
      "outputs": [],
      "source": [
        "df.Score.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srMcte0htXzk"
      },
      "outputs": [],
      "source": [
        "top_ProductId= df.ProductId.value_counts()\n",
        "top_ProductId.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx_ycqXutXzl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[10, 5])\n",
        "sns.barplot(x = top_ProductId.index[:5] , y=top_ProductId.head() )\n",
        "plt.title('Top 5 top_ProductId');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ji1wDm3MtXzm"
      },
      "outputs": [],
      "source": [
        "top_Score= df.UserId.value_counts()\n",
        "top_Score.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19joxT6ttXzm"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[10, 5])\n",
        "sns.barplot(x = top_Score.index[:5] , y=top_Score.head() )\n",
        "plt.title('Top 5 top_Score');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I78-ytyrtXzn"
      },
      "outputs": [],
      "source": [
        "# Drop all 'HelpfulnessNumerator','HelpfulnessDenominator','UserId','ProfileName','Time'\n",
        "\n",
        "df.drop(['HelpfulnessNumerator','HelpfulnessDenominator','UserId','ProfileName','Time'], axis= 1, inplace= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CorzGssNtXzo"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcBIgXOctXzo"
      },
      "source": [
        "#  NLTK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gh_wpdct7M9j"
      },
      "outputs": [],
      "source": [
        "example = df['Text'][5]\n",
        "print('this example from data:')\n",
        "print('')\n",
        "print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-emkNYc7TWC"
      },
      "outputs": [],
      "source": [
        "tokens=nltk.word_tokenize(example)\n",
        "tokens[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-x46IBdr7cbq"
      },
      "outputs": [],
      "source": [
        "tagged = nltk.pos_tag(tokens)\n",
        "tagged[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9y5P2patXzr"
      },
      "outputs": [],
      "source": [
        "from nltk import ngrams\n",
        "\n",
        "sent=(example)\n",
        "n=2\n",
        "unigrams=ngrams(sent.split(),n)\n",
        "for grams in unigrams:\n",
        "  print(grams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHbHf-Cr-NHn"
      },
      "outputs": [],
      "source": [
        "entities = nltk.chunk.ne_chunk(tagged)\n",
        "entities.pprint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STBrP1sXtXzt"
      },
      "source": [
        "# Step 1. VADER Seniment Scoring\n",
        "We will use NLTK's SentimentIntensityAnalyzer to get the neg/neu/pos scores of the text.\n",
        "\n",
        "This uses a \"bag of words\" approach:\n",
        "\n",
        "Stop words are removed\n",
        "\n",
        "each word is scored and combined to a total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXS0wspy-Sym"
      },
      "outputs": [],
      "source": [
        "nltk.download('vader_lexicon')\n",
        "#lexicon is a pre-trained sentiment analysis model included in NLTK.\n",
        "\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "# is a sentiment analysis tool based on the VADER lexicon.\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "#provides a progress bar for iterating over loops\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "# This object allows you to perform sentiment analysis on text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mp9QmhBt-ZyU"
      },
      "outputs": [],
      "source": [
        "sia.polarity_scores('I am so happy!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBhAWf2--vpd"
      },
      "outputs": [],
      "source": [
        "sia.polarity_scores('This is the worst thing ever.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUVViJtY-2CY"
      },
      "outputs": [],
      "source": [
        "sia.polarity_scores(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDhdxxBf-8BI"
      },
      "outputs": [],
      "source": [
        "# Run the polarity score on the entire dataset\n",
        "# For each row, it extracts the 'Text' and 'Id' columns' values and performs sentiment analysis\n",
        "####################################\n",
        "\n",
        "res = {}\n",
        "\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "# tqdm is used to display a progress bar for the loop, indicating the progress of the iteration.\n",
        "\n",
        "    text = row['Text']\n",
        "    #The line extracts the value of the 'Text' column from the current row for sentiment analysis\n",
        "\n",
        "    myid = row['Id']\n",
        "\n",
        "    res[myid] = sia.polarity_scores(text)\n",
        "    #This line performs sentiment analysis on the text using the sia.polarity_scores() method\n",
        "    #The resulting sentiment scores (compound, positive, negative, and neutral)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAkvdFTN_A1q"
      },
      "outputs": [],
      "source": [
        "#performs additional operations on the sentiment scores\n",
        "###############################################\n",
        "\n",
        "vaders = pd.DataFrame(res).T\n",
        "#df by res dictionary name vader\n",
        "#T transposes the DataFrame to have the sentiment scores as columns and the 'Id' values as rows.\n",
        "\n",
        "vaders = vaders.reset_index().rename(columns={'index': 'Id'})\n",
        "#changes the column name from 'index' to 'Id'.\n",
        "\n",
        "vaders = vaders.merge(df, how='left')\n",
        "#merge vaders DataFrame and the original DataFrame df.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9igvINm_Mby"
      },
      "outputs": [],
      "source": [
        "# Now we have sentiment score and metadata\n",
        "vaders.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkT9HW8HtX0G"
      },
      "source": [
        "# Plot VADER results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdhIuNGh_P7v"
      },
      "outputs": [],
      "source": [
        "ax = sns.barplot(data=vaders, x='Score', y='compound')\n",
        "# creates a bar plot data is vaders ,x_label is \"score\",y_label is \"compound\".\n",
        "\n",
        "ax.set_title('Compund Score by Amazon Star Review')\n",
        "#title\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_rYHpDf_Umr"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(12, 3))\n",
        "\n",
        "#one row and three columns of subplots\n",
        "#figsize is 12w , 3h\n",
        "sns.barplot(data=vaders, x='Score', y='pos', ax=axs[0])\n",
        "sns.barplot(data=vaders, x='Score', y='neu', ax=axs[1])\n",
        "sns.barplot(data=vaders, x='Score', y='neg', ax=axs[2])\n",
        "axs[0].set_title('Positive')\n",
        "axs[1].set_title('Neutral')\n",
        "axs[2].set_title('Negative')\n",
        "plt.tight_layout()\n",
        "#adjusts the spacing between subplots\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK26lZWgtX0J"
      },
      "source": [
        "# Step 3. Roberta Pretrained Model\n",
        "\n",
        "Use a model trained of a large corpus of data.\n",
        "\n",
        "Transformer model accounts for the words but also the context related to other words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc2LraEA_cda"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "#The AutoTokenizer class is used for tokenizing text,\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "#his class provides a pre-trained model\n",
        "\n",
        "from scipy.special import softmax\n",
        "#The scipy.special module provides a wide range\n",
        "#of mathematical functions that are not included in the core Python math module.\n",
        "# Softmax is commonly applied to convert raw scores into probability distributions,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUWNO0S7_jbL"
      },
      "outputs": [],
      "source": [
        "#initializes a tokenizer and a pre-trained model\n",
        "#####################################################\n",
        "\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "#sentiment analysis model trained on Twitter data using the Roberta architecture.\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "#The tokenizer is responsible for converting text input into numerical tokens that can be understood by the model.\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "\n",
        "#This particular class is designed for sequence classification tasks,\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GD6322URAsTP"
      },
      "outputs": [],
      "source": [
        "# VADER results on example\n",
        "print(example)\n",
        "sia.polarity_scores(example)\n",
        "#perform sentiment analysis on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hzShrSmA4oR"
      },
      "outputs": [],
      "source": [
        "# Run for Roberta Model\n",
        "#######################\n",
        "\n",
        "encoded_text = tokenizer(example, return_tensors='pt')\n",
        "#The return_tensors='pt' specifies that the tokenizer should return PyTorch tensors as output.\n",
        "\n",
        "output = model(**encoded_text)\n",
        "# passes the encoded_text to the pre-trained model for sequence classification.\n",
        "\n",
        "scores = output[0][0].detach().numpy()\n",
        "#retrieves the output scores from the model. The model's output is a tensor,\n",
        "#.detach().numpy() is used to convert the tensor to a NumPy array.\n",
        "\n",
        "scores = softmax(scores)\n",
        "#function converts the scores into probabilities\n",
        "\n",
        "scores_dict = {\n",
        "\n",
        "    'roberta_neg' : scores[0],\n",
        "    'roberta_neu' : scores[1],\n",
        "    'roberta_pos' : scores[2]\n",
        "   }\n",
        "print(scores_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHOsu5CXA_Cf"
      },
      "outputs": [],
      "source": [
        "#polarity_scores_roberta that takes an example text as input and returns a dictionary of sentiment scores.\n",
        "#######################################\n",
        "\n",
        "def polarity_scores_roberta(example):\n",
        "    encoded_text = tokenizer(example, return_tensors='pt')\n",
        "    ##The return_tensors='pt' parameter specifies that the tokenizer should return PyTorch tensors as output.\n",
        "\n",
        "    output = model(**encoded_text)\n",
        "\n",
        "\n",
        "    scores = output[0][0].detach().numpy()\n",
        "    #retrieves the output scores from the model. The model's output is a tensor,\n",
        "    #.detach().numpy() is used to convert the tensor to a NumPy array.\n",
        "\n",
        "    scores = softmax(scores)\n",
        "    ##function converts the scores into probabilities,\n",
        "\n",
        "    scores_dict = {\n",
        "        'roberta_neg' : scores[0],\n",
        "        'roberta_neu' : scores[1],\n",
        "        'roberta_pos' : scores[2]\n",
        "        #stores the sentiment scores under different keys.\n",
        "\n",
        "    }\n",
        "    return scores_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MZT1M-IBDAs"
      },
      "outputs": [],
      "source": [
        "#plies sentiment analysis using both VADER and a pre-trained RoBERTa model to each text in the DataFrame.\n",
        "\n",
        "res = {}\n",
        "\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "#The tqdm function is used to display a progress bar during the iteration.\n",
        "\n",
        "    try:\n",
        "        #starts a try-except block,\n",
        "\n",
        "\n",
        "        text = row['Text']\n",
        "        myid = row['Id']\n",
        "        #res retrieve the text and ID values from the current row of the DataFrame.\n",
        "\n",
        "        vader_result = sia.polarity_scores(text)\n",
        "        # applies VADER sentiment analysis using the SentimentIntensityAnalyzer object sia to the text,\n",
        "\n",
        "        vader_result_rename = {}\n",
        "\n",
        "        for key, value in vader_result.items():\n",
        "            # loop over each key-value pair\n",
        "\n",
        "            vader_result_rename[f\"vader_{key}\"] = value\n",
        "            # renames each key in the vader_result\n",
        "\n",
        "\n",
        "        roberta_result = polarity_scores_roberta(text)\n",
        "        #passing the text , and assigns the returned sentiment scores dictionary to roberta_result.\n",
        "\n",
        "        both = {**vader_result_rename, **roberta_result}\n",
        "        #combines the  results\n",
        "\n",
        "        res[myid] = both\n",
        "        #dds  results (both) to the res dictionary, with the ID (myid) as the key.\n",
        "\n",
        "    except RuntimeError:\n",
        "        #except block is triggered if a RuntimeError occurs during the sentiment analysis process.\n",
        "\n",
        "        print(f'Broke for id {myid}')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sDLTDOtBKuD"
      },
      "outputs": [],
      "source": [
        "#takes the sentiment analysis results stored in the res dictionary and merges them with the original DataFrame (df)\n",
        "# to create a new DataFrame (results_df) that contains the sentiment analysis results alongside the original data\n",
        "\n",
        "results_df = pd.DataFrame(res).T\n",
        "#T transposes the DataFrame so that the sentiment analysis results are aligned as columns.\n",
        "\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'Id'})\n",
        "\n",
        "results_df = results_df.merge(df, how='left')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy3ZIMiutX0S"
      },
      "source": [
        "# Compare Scores between models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptr-q4QtCgOc"
      },
      "outputs": [],
      "source": [
        "print('the columns of data is : ')\n",
        "results_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVLkxOgJtX0U"
      },
      "source": [
        "# Step 3. Combine and compare¶\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Jpx-rMVCkBA"
      },
      "outputs": [],
      "source": [
        "###Combine and compare\n",
        "sns.pairplot(data=results_df,\n",
        "             vars=['vader_neg', 'vader_neu', 'vader_pos',\n",
        "                  'roberta_neg', 'roberta_neu', 'roberta_pos'],\n",
        "            hue='Score',\n",
        "             #set to 'Score', which means that the points in the plot will be colored according to the 'Score' variable\n",
        "\n",
        "             palette='tab10')\n",
        "             #sets the color palette to 'tab10'.\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7W9JMrftX0W"
      },
      "source": [
        "# Step 4: Review Examples:\n",
        "        \n",
        "Positive 1-Star and Negative 5-Star Reviews\n",
        "\n",
        "Lets look at some examples where the model scoring and review score differ the most."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzpsjg10DEYu"
      },
      "outputs": [],
      "source": [
        "#Review Examples\n",
        "\n",
        "results_df.query('Score == 1') \\\n",
        "    .sort_values('roberta_pos', ascending=False)['Text'].values[0]\n",
        "#filters the DataFrame results_df to include only rows where the 'Score' column is equal to 1.\n",
        "# This creates a subset of the DataFrame containing positive reviews.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fZMHkclDas-"
      },
      "outputs": [],
      "source": [
        " results_df.query('Score == 1') \\\n",
        "    .sort_values('vader_pos', ascending=False)['Text'].values[0]\n",
        "# sorts the reviews based on the positivity score predicted by the VADER model,\n",
        "#['Text'].values[0]: This line selects the 'Text' column from the sorted subset and retrieves the value of the first element.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6ruRls4De0p"
      },
      "outputs": [],
      "source": [
        "# negative sentiment 5-Star view\n",
        "results_df.query('Score == 5') \\\n",
        "    .sort_values('roberta_neg', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpZDb7uRDkJD"
      },
      "outputs": [],
      "source": [
        "results_df.query('Score == 5') \\\n",
        "    .sort_values('vader_neg', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b_CbxaZtX0b"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "#function is a high-level interface for executing various NLP tasks using pre-trained models.\n",
        "\n",
        "sent_pipeline = pipeline(\"sentiment-analysis\")\n",
        "    #Sentiment Analysis is a supervised Machine Learning technique that is used to analyze and predict\n",
        "    #the polarity of sentiments within a text (either positive or negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OZBpOAdD0-W"
      },
      "outputs": [],
      "source": [
        "print('your Review is  ',sent_pipeline('I love sentiment analysis!'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4G7UN6UEAtr"
      },
      "outputs": [],
      "source": [
        "print('your Review is  ',sent_pipeline('Make sure to like and subscribe!'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcBa2Bb2EFJT"
      },
      "outputs": [],
      "source": [
        "print('your Review is  ',sent_pipeline('booo'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC4m9PDQEIbb"
      },
      "outputs": [],
      "source": [
        "print('your Review is  ',sent_pipeline('i care about hotdog'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy1nahr1EUQU"
      },
      "outputs": [],
      "source": [
        "print('your Review is  ',sent_pipeline('احب الطعام الذى يحتوى على الخضراوات'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfvhJIeVIKrg"
      },
      "outputs": [],
      "source": [
        "#spanish\n",
        "print('your Review is  ',sent_pipeline('no me gusta la comida'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC5UtRNQI7VU"
      },
      "outputs": [],
      "source": [
        "print('your Review is  ',sent_pipeline('je naime pas la nourriture'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwQsRxUhJWac"
      },
      "outputs": [],
      "source": [
        "print('your Review is  ',sent_pipeline('Jaime la nourriture'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L8YUPWnJmH9"
      },
      "outputs": [],
      "source": [
        "print('your Review is  ',sent_pipeline('/content/Reviews.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLmJFLunzUrF"
      },
      "source": [
        "# The End"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK1KZLH1zrzA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}